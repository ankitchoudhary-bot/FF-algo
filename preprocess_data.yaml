name: Preprocess MNIST Dataset
description: Normalizes MNIST images and casts labels; prepares TF datasets.

inputs:
  - {name: x_train, type: Dataset}
  - {name: y_train, type: Dataset}
  - {name: x_test, type: Dataset}
  - {name: y_test, type: Dataset}
  - {name: Flatten_flag, type: Bool, default: true}

outputs:
  - {name: x_train, type: Dataset}
  - {name: x_test, type: Dataset}
  - {name: y_train, type: Dataset}
  - {name: y_test, type: Dataset}
  # - {name: train_dataset, type: Dataset}
  # - {name: test_dataset, type: Dataset}

implementation:
  container:
    image: python:3.8
    command:
      - sh
      - -c
      - |
        python3 -m pip install --quiet numpy tensorflow
        exec python3 -u - "$@"
      - |
        import numpy as np
        import tensorflow as tf
        import argparse

        parser = argparse.ArgumentParser()
        parser.add_argument('--x_train', required=True)
        parser.add_argument('--y_train', required=True)
        parser.add_argument('--x_test', required=True)
        parser.add_argument('--y_test', required=True)
        parser.add_argument('--x_train_out', required=True)
        parser.add_argument('--x_test_out', required=True)
        parser.add_argument('--y_train_out', required=True)
        parser.add_argument('--y_test_out', required=True)
        # parser.add_argument('--train_dataset', required=True)
        # parser.add_argument('--test_dataset', required=True)
        parser.add_argument('--Flatten_flag', required=True)
        args = parser.parse_args()

        Flatten_flag = args.Flatten_flag.lower() == 'true'

        x_train = np.load(args.x_train).astype(np.float32) / 255.0
        x_test = np.load(args.x_test).astype(np.float32) / 255.0
        y_train = np.load(args.y_train).astype(np.int32)
        y_test = np.load(args.y_test).astype(np.int32)

        if Flatten_flag:
          x_train=x_train.reshape((x_train.shape[0],-1))
          x_test=x_test.reshape((x_test.shape[0],-1))

        # Save preprocessed arrays
        np.save(args.x_train_out, x_train)
        np.save(args.x_test_out, x_test)
        np.save(args.y_train_out, y_train)
        np.save(args.y_test_out, y_test)

        # Convert to TensorFlow datasets
        # train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(60000)
        # test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test)).batch(10000)

        # Save datasets as .npz (TF dataset can't be saved directly; this is a common workaround)
        # tf.data.experimental.save(train_dataset, args.train_dataset)
        # tf.data.experimental.save(test_dataset, args.test_dataset)

    args:
      - --x_train
      - {inputPath: x_train}
      - --y_train
      - {inputPath: y_train}
      - --x_test
      - {inputPath: x_test}
      - --y_test
      - {inputPath: y_test}
      - --Flatten_flag
      - {inputValue: Flatten_flag}
      - --x_train_out
      - {outputPath: x_train}
      - --x_test_out
      - {outputPath: x_test}
      - --y_train_out
      - {outputPath: y_train}
      - --y_test_out
      - {outputPath: y_test}
      # - --train_dataset
      # - {outputPath: train_dataset}
      # - --test_dataset
      # - {outputPath: test_dataset}
